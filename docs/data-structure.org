* Client data structures
  - wl_global :: the global structure that fits the need of an wayland client.
		 It contains things like ~wl_shm~, ~wl_shm_format~,
		 ~wl_compositor~, ~wl_display~.
    * Inputs :: I only have one input per client, fair enough, why
    would you need two seats if only one person operates it.

  - tw_event_loop :: introduced for ~tw_shell~ to handle system generated events
		     like time lapse and wayland protocol events.
    * tw_event :: this leads to another interface for use to
    create its own event and watch the event. It didn't go as
    far as the ~wl_protocols~ where you create custom protocols
    and have handlers for them.

  - shm_pool :: the allocator for shared buffers, binds to ~wl_buffer~.

Then there are the UI elements
** UIs
   - app_surface :: now you have an app surface, it kinda binds to an
		    ~wl_surface~. The surface has it implementation of buffer
		    and input events, it has the data but no actual methods to
		    interact with it. ~app_surface~ was first created for
		    distinguishing background surface and panel surface. So in a
		    sense, now we have three different kinds of ~app_surface~,
		    background, panel, widget.

     - As an ~app_surface~, it has it's own ~<x,y,w,h>~ values.
     - It also has input-events, to generate the a new frame.


   - tw_ui :: plays the role like ~wl_shell_surface~ as a bridge between server
	      and clients. Otherwise server does not know how to update it. With
	      that in mind, the ~app_surface.proxy~ is the ~tw_ui~.
   - however, app_surface is designed to work with different proxies, ~tw_ui~
     and ~wl_shell_surface~ or ~xdg_shell_surface~ should all work, it is an
     wrap around ~wl_surface~ and provides convenient methods for commiting
     surface and do a new frame.

     + but you know not everyting relates to a surface is about frame, would it
       be able to update something without drawing a new frame? We would not
       know, you can still try to draw it, then if there is no change at
       all. Then skip the GPU pipeline.

       Another problem I have now is the treatment of frame-function in the
       ~app_surface~. If you decide to provide a callback for it, then how will
       the nuklear clients has its draw function? It is not just imposible, one
       protential hack would be having user-data section in the in app_surface
       implementation, but you would need to allocate different size of


*** UI implementation
    - background :: background is picture reading and posting, it could be
		    implemented as animation, by calling a frame.

    - nuklear_backend :: this GUI library is implemented with OpenGL, it should
	 implement an app_surface like a sub class, then use it users can use
	 simply app_surface to operate.

    - icon :: This is one that complicates the implementation. It does not have
	      its own data, but also need a frame. The frame is triggered by
	      events.

*** The pitfalls of app_surface
~app_surface~ has evolved for too long and too much overhead (Not as much as
~nk_backend~). It has three constructors, know the EGL and shared buffer. It has
init but only does part of the job. I should really make it whole, init with
different implementation and that is it.

If app_surface created with buffer, you call ~app_surface_fadc~. Otherwise it is
done by subroutines. I don't like it. The commit job should be here.

It also has its own input handler as an main feature. The initial design of the
~app_surface~ was too limited, just as a surface with two ~wl_buffer~ and do the
swap. It has no concept in drawing. The ~wl_buffer~ is bind to another buffer
structure and user uses that for drawing. Since both interface is exposed to
users, it can be confusing. The ideal case, ~app_surface~ should provide an
a frame callback which gives users the buffer to draw on. And users of the
interface should be worry free from which buffer I am using. The double buffer
case is that people is worried about frame losing if the none of the frame is
not available. You can always commit using new buffers, but if committing too
much then it will make it to see the animation. But since I am not driving
animation here, this is kinda useless.


*** frame vs other event.
I suppose if you do the animation, then you need to call the ~commit~ plus a
~frame~ in the next done event.

If you read what ~libweston~ is doing, they take the ~frame_callback~ insert to
surface ~frame_callback_list~. And in the ~weston_output_repaint~ function. They
take all the ~frame_callback~ from all the committed views then send them
all. The release of the buffer is totally not related to it, especially if you
don't even use an ~wl_buffer~.

But second thought, don't you find the frame done callback is no different than
other input callback? They are events as well. The parameter is the time(msecs)

There are differences, the frame callback does not really work unless you
commit. So the surface has to commit for the first time. So the procedure is
that you have to apply a frame, then commit for the first time. In your frame
callback, do the same.

*** nuklear backend
The nuklear backend is the implementation of an GUI with the ~wl_buffer~ from
~app_surface~. It was designed to support different surface at the same time
then I found out I cannot really do it.

** Taiwins Shell specific structure.
